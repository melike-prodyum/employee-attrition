"""
Employee Attrition Prediction - Decision Tree Model
Ã‡alÄ±ÅŸan iÅŸten ayrÄ±lma tahmini iÃ§in Decision Tree modeli
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
    roc_auc_score
)
import warnings
warnings.filterwarnings('ignore')

# Ortak utility fonksiyonlarÄ±nÄ± import et
from data_utils import (
    load_data,
    print_data_info,
    prepare_features,
    get_column_types,
    fill_missing_values,
    apply_one_hot_encoding,
    create_output_directory,
    create_submission_file
)
from evaluation_utils import (
    print_metrics,
    print_classification_report,
    print_confusion_matrix,
    print_feature_importance
)

# GÃ¶rselleÅŸtirme ayarlarÄ±
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*70)
print("EMPLOYEE ATTRITION PREDICTION - DECISION TREE MODEL")
print("="*70)

# ============================================================================
# 1. VERÄ° YÃœKLEME VE KEÅÄ°F ANALÄ°ZÄ°
# ============================================================================
print("\n[1] Veri YÃ¼kleme ve KeÅŸif Analizi")
print("-"*70)

# Veri setlerini yÃ¼kle
train_df, test_df, submission = load_data()
print_data_info(train_df, test_df)

# ============================================================================
# 2. VERÄ° Ã–N Ä°ÅLEME
# ============================================================================
print("\n[2] Veri Ã–n Ä°ÅŸleme")
print("-"*70)

# Features ve target'Ä± ayÄ±r
X_train, X_test, y, train_ids, test_ids = prepare_features(train_df, test_df)

print(f"âœ“ Feature sayÄ±sÄ±: {X_train.shape[1]}")

# Kategorik ve numerik sÃ¼tunlarÄ± ayÄ±r
categorical_cols, numerical_cols = get_column_types(X_train)

print(f"âœ“ Kategorik sÃ¼tunlar ({len(categorical_cols)}): {categorical_cols}")
print(f"âœ“ Numerik sÃ¼tunlar ({len(numerical_cols)}): {numerical_cols}")

# Eksik deÄŸerleri doldur
X_train, X_test = fill_missing_values(X_train, X_test, categorical_cols, numerical_cols)

# Kategorik deÄŸiÅŸkenleri One-Hot Encoding ile encode et
X_train, X_test = apply_one_hot_encoding(X_train, X_test, categorical_cols, verbose='detailed')

print(f"\nâœ“ Veri Ã¶n iÅŸleme tamamlandÄ±!")
print(f"âœ“ Train shape: {X_train.shape}")
print(f"âœ“ Test shape: {X_test.shape}")

# ============================================================================
# 3. DECISION TREE MODELÄ° OLUÅTURMA
# ============================================================================
print("\n[3] Decision Tree Modeli OluÅŸturma")
print("-"*70)

# Train-validation split
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y, test_size=0.2, random_state=42, stratify=y
)

print(f"âœ“ Train set: {X_train_split.shape[0]} Ã¶rnekleri")
print(f"âœ“ Validation set: {X_val_split.shape[0]} Ã¶rnekleri")

# Decision Tree modeli - model_builders'dan al
from model_builders import build_decision_tree, get_decision_tree_params

dt_params = get_decision_tree_params()
print("\nğŸŒ³ Decision Tree parametreleri:")
print(f"  - max_depth: {dt_params['max_depth']} (aÄŸacÄ±n maksimum derinliÄŸi)")
print(f"  - min_samples_split: {dt_params['min_samples_split']} (dallanma iÃ§in minimum Ã¶rnek sayÄ±sÄ±)")
print(f"  - min_samples_leaf: {dt_params['min_samples_leaf']} (yaprak dÃ¼ÄŸÃ¼mdeki minimum Ã¶rnek sayÄ±sÄ±)")
print(f"  - criterion: {dt_params['criterion']} (bÃ¶lÃ¼nme kriteri)")
print(f"  - random_state: {dt_params['random_state']}")
print(f"  - class_weight: {dt_params['class_weight']} (dengesiz veri iÃ§in)")

dt_model = build_decision_tree()

print("\nâ³ Model eÄŸitiliyor...")
dt_model.fit(X_train_split, y_train_split)
print("âœ“ Model eÄŸitimi tamamlandÄ±!")

# Model bilgileri
print(f"\nğŸ“Š Model Ã–zellikleri:")
print(f"  - AÄŸaÃ§ derinliÄŸi: {dt_model.get_depth()}")
print(f"  - Yaprak sayÄ±sÄ±: {dt_model.get_n_leaves()}")
print(f"  - Toplam dÃ¼ÄŸÃ¼m sayÄ±sÄ±: {dt_model.tree_.node_count}")

# ============================================================================
# 4. MODEL DEÄERLENDÄ°RME
# ============================================================================
print("\n[4] Model DeÄŸerlendirme")
print("-"*70)

# Tahminler
y_train_pred = dt_model.predict(X_train_split)
y_val_pred = dt_model.predict(X_val_split)
y_train_proba = dt_model.predict_proba(X_train_split)[:, 1]
y_val_proba = dt_model.predict_proba(X_val_split)[:, 1]

# Metrikler
print("\nğŸ“ˆ PERFORMANS METRÄ°KLERÄ°")
print("="*70)

print_metrics(y_train_split, y_train_pred, y_train_proba, 'Train')
print_metrics(y_val_split, y_val_pred, y_val_proba, 'Validation')

# Classification Report
print_classification_report(y_val_split, y_val_pred)

# Confusion Matrix
cm = print_confusion_matrix(y_val_split, y_val_pred)

# Feature Importance
feature_importance = print_feature_importance(dt_model, X_train.columns)

# ============================================================================
# 5. GÃ–RSELLEÅTÄ°RME
# ============================================================================
print("\n[5] GÃ¶rselleÅŸtirmeler OluÅŸturuluyor...")
print("-"*70)

# outputs/decision_tree klasÃ¶rÃ¼nÃ¼ oluÅŸtur
output_dir = create_output_directory('decision_tree')

# Figure oluÅŸtur - BirleÅŸik gÃ¶rsel
fig = plt.figure(figsize=(20, 12))

# 1. Confusion Matrix
ax1 = plt.subplot(2, 3, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')

# 2. Feature Importance
ax2 = plt.subplot(2, 3, 2)
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#c0392b', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=9, fontweight='bold')
plt.gca().invert_yaxis()

# 3. ROC Curve
ax3 = plt.subplot(2, 3, 3)
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#c0392b')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. Target Distribution
ax4 = plt.subplot(2, 3, 4)
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')

# 5. Accuracy Comparison
ax5 = plt.subplot(2, 3, 5)
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#e74c3c', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#c0392b', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')

# 6. Decision Tree yapÄ±sÄ±nÄ± gÃ¶ster (basitleÅŸtirilmiÅŸ)
ax6 = plt.subplot(2, 3, 6)
plot_tree(dt_model, 
          max_depth=3,  # GÃ¶rselleÅŸtirme iÃ§in ilk 3 seviye
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=7,
          rounded=True)
plt.title('Decision Tree YapÄ±sÄ± (Ä°lk 3 Seviye)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig(f'{output_dir}/decision_tree_analysis.png', dpi=300, bbox_inches='tight')
print("âœ“ BirleÅŸik grafik kaydedildi: outputs/decision_tree/decision_tree_analysis.png")

# ============================================================================
# AYRI AYRI GRAFÄ°KLER
# ============================================================================
print("\nğŸ“Š Grafikleri ayrÄ± ayrÄ± kaydediyorum...")

# 1. Confusion Matrix - AyrÄ±
fig1 = plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Confusion Matrix kaydedildi")

# 2. Feature Importance - AyrÄ±
fig2 = plt.figure(figsize=(10, 8))
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#c0392b', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=10, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Feature Importance kaydedildi")

# 3. ROC Curve - AyrÄ±
fig3 = plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#c0392b')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_roc_curve.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ ROC Curve kaydedildi")

# 4. Target Distribution - AyrÄ±
fig4 = plt.figure(figsize=(8, 6))
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_target_distribution.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Target Distribution kaydedildi")

# 5. Performance Metrics - AyrÄ±
fig5 = plt.figure(figsize=(10, 6))
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#e74c3c', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#c0392b', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_performance_metrics.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Performance Metrics kaydedildi")

# 6. Tree Structure (simplified) - AyrÄ±
fig6 = plt.figure(figsize=(20, 12))
plot_tree(dt_model, 
          max_depth=3,
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=9,
          rounded=True)
plt.title('Decision Tree YapÄ±sÄ± (Ä°lk 3 Seviye)', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig(f'{output_dir}/dt_tree_structure_simple.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Tree Structure (simplified) kaydedildi")

# Daha detaylÄ± aÄŸaÃ§ gÃ¶rselleÅŸtirmesi
fig7 = plt.figure(figsize=(25, 15))
plot_tree(dt_model, 
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=10,
          rounded=True,
          proportion=True)
plt.title('Decision Tree - Tam YapÄ±', fontsize=16, fontweight='bold', pad=20)
plt.savefig(f'{output_dir}/decision_tree_full.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Tam aÄŸaÃ§ gÃ¶rselleÅŸtirmesi kaydedildi")

print("\nâœ“ TÃ¼m grafikler hem birleÅŸik hem de ayrÄ± ayrÄ± kaydedildi!")

# ============================================================================
# 6. TEST VERÄ°SÄ° Ä°Ã‡Ä°N TAHMÄ°NLER
# ============================================================================
print("\n[6] Test Verisi Tahminleri")
print("-"*70)

# TÃ¼m train verisi ile son modeli eÄŸit
print("â³ Final model tÃ¼m train verisi ile eÄŸitiliyor...")
final_model = build_decision_tree()
final_model.fit(X_train, y)
print("âœ“ Final model eÄŸitimi tamamlandÄ±!")

# Submission dosyasÄ±nÄ± hazÄ±rla
test_predictions, submission_df = create_submission_file(
    final_model, X_test, submission, 'submission_decision_tree.csv'
)
print(f"âœ“ Submission dosyasÄ± oluÅŸturuldu: submissions/submission_decision_tree.csv")
print(f"âœ“ Tahmin edilen test Ã¶rnekleri: {len(test_predictions)}")
print(f"\nTahmin Ä°statistikleri:")
print(f"  â€¢ Ortalama: {test_predictions.mean():.4f}")
print(f"  â€¢ Std:      {test_predictions.std():.4f}")
print(f"  â€¢ Min:      {test_predictions.min():.4f}")
print(f"  â€¢ Max:      {test_predictions.max():.4f}")

# ============================================================================
# Ã–ZET
# ============================================================================
print("\n" + "="*70)
print("MODEL Ã–ZETI")
print("="*70)
print(f"\nâœ“ Model Tipi: Decision Tree Classifier")
print(f"âœ“ AÄŸaÃ§ DerinliÄŸi: {final_model.get_depth()}")
print(f"âœ“ Yaprak SayÄ±sÄ±: {final_model.get_n_leaves()}")
print(f"âœ“ Validation Accuracy: {accuracy_score(y_val_split, y_val_pred):.4f}")
print(f"âœ“ Validation ROC-AUC: {roc_auc_score(y_val_split, y_val_proba):.4f}")
print(f"\nğŸ“ OluÅŸturulan Dosyalar:")
print(f"  BirleÅŸik GÃ¶rsel:")
print(f"    â€¢ outputs/decision_tree/decision_tree_analysis.png - Genel analiz grafikleri")
print(f"  AyrÄ± GÃ¶rseller:")
print(f"    â€¢ outputs/decision_tree/dt_confusion_matrix.png")
print(f"    â€¢ outputs/decision_tree/dt_feature_importance.png")
print(f"    â€¢ outputs/decision_tree/dt_roc_curve.png")
print(f"    â€¢ outputs/decision_tree/dt_target_distribution.png")
print(f"    â€¢ outputs/decision_tree/dt_performance_metrics.png")
print(f"    â€¢ outputs/decision_tree/dt_tree_structure_simple.png")
print(f"    â€¢ outputs/decision_tree/decision_tree_full.png")
print(f"  Submission:")
print(f"    â€¢ submissions/submission_decision_tree.csv")

print("\n" + "="*70)
print("âœ… Ä°ÅLEM TAMAMLANDI!")
print("="*70)
print("\nğŸ’¡ Not: Decision Tree basit ve yorumlanabilir bir modeldir.")
print("   Random Forest ile karÅŸÄ±laÅŸtÄ±rma yapmak iÃ§in birden fazla")
print("   aÄŸacÄ±n ensemble'Ä±nÄ± kullanmanÄ±z gerekecek.")
print("="*70)
