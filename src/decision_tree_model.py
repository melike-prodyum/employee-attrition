"""
Employee Attrition Prediction - Decision Tree Model
Ã‡alÄ±ÅŸan iÅŸten ayrÄ±lma tahmini iÃ§in Decision Tree modeli
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve
)
import warnings
warnings.filterwarnings('ignore')

# GÃ¶rselleÅŸtirme ayarlarÄ±
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*70)
print("EMPLOYEE ATTRITION PREDICTION - DECISION TREE MODEL")
print("="*70)

# ============================================================================
# 1. VERÄ° YÃœKLEME VE KEÅÄ°F ANALÄ°ZÄ°
# ============================================================================
print("\n[1] Veri YÃ¼kleme ve KeÅŸif Analizi")
print("-"*70)

# Veri setlerini yÃ¼kle
import os
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
train_df = pd.read_csv(os.path.join(project_root, 'data', 'aug_train.csv'))
test_df = pd.read_csv(os.path.join(project_root, 'data', 'aug_test.csv'))
submission = pd.read_csv(os.path.join(project_root, 'data', 'sample_submission.csv'))

print(f"âœ“ Train veri seti boyutu: {train_df.shape}")
print(f"âœ“ Test veri seti boyutu: {test_df.shape}")
print(f"\nSÃ¼tunlar: {list(train_df.columns)}")

# Target daÄŸÄ±lÄ±mÄ±
print(f"\nğŸ“Š Target DaÄŸÄ±lÄ±mÄ±:")
print(train_df['target'].value_counts())
print(f"Target oranÄ±: {train_df['target'].value_counts(normalize=True)}")

# Eksik deÄŸerler
print(f"\nğŸ“‹ Eksik DeÄŸerler:")
missing = train_df.isnull().sum()
missing_pct = (missing / len(train_df)) * 100
missing_df = pd.DataFrame({
    'Eksik SayÄ±sÄ±': missing,
    'YÃ¼zde': missing_pct
}).sort_values('Eksik SayÄ±sÄ±', ascending=False)
print(missing_df[missing_df['Eksik SayÄ±sÄ±'] > 0])

# ============================================================================
# 2. VERÄ° Ã–N Ä°ÅLEME
# ============================================================================
print("\n[2] Veri Ã–n Ä°ÅŸleme")
print("-"*70)

# enrollee_id'yi ayÄ±r (model iÃ§in kullanÄ±lmayacak)
train_ids = train_df['enrollee_id']
test_ids = test_df['enrollee_id']

# Target deÄŸiÅŸkeni ayÄ±r
y = train_df['target']
X_train = train_df.drop(['enrollee_id', 'target'], axis=1)
X_test = test_df.drop(['enrollee_id'], axis=1)

print(f"âœ“ Feature sayÄ±sÄ±: {X_train.shape[1]}")

# Kategorik ve numerik sÃ¼tunlarÄ± ayÄ±r
categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()
numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

print(f"âœ“ Kategorik sÃ¼tunlar ({len(categorical_cols)}): {categorical_cols}")
print(f"âœ“ Numerik sÃ¼tunlar ({len(numerical_cols)}): {numerical_cols}")

# Eksik deÄŸerleri doldur
print("\nğŸ”§ Eksik deÄŸerleri doldurma:")

# Numerik sÃ¼tunlar iÃ§in median
for col in numerical_cols:
    if X_train[col].isnull().sum() > 0:
        median_val = X_train[col].median()
        X_train[col].fillna(median_val, inplace=True)
        X_test[col].fillna(median_val, inplace=True)
        print(f"  - {col}: median ile dolduruldu")

# Kategorik sÃ¼tunlar iÃ§in mode (en sÄ±k gÃ¶rÃ¼len deÄŸer)
for col in categorical_cols:
    if X_train[col].isnull().sum() > 0:
        mode_val = X_train[col].mode()[0] if not X_train[col].mode().empty else 'Unknown'
        X_train[col].fillna(mode_val, inplace=True)
        X_test[col].fillna(mode_val, inplace=True)
        print(f"  - {col}: mode ile dolduruldu")

# Kategorik deÄŸiÅŸkenleri One-Hot Encoding ile encode et
print("\nğŸ”§ Kategorik deÄŸiÅŸkenleri One-Hot Encoding ile encode etme:")

if categorical_cols:
    # One-Hot Encoding uygula
    X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=False)
    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=False)
    
    # Train ve test'te aynÄ± sÃ¼tunlarÄ±n olmasÄ±nÄ± saÄŸla
    # Test'te olmayan sÃ¼tunlarÄ± ekle (0 deÄŸeriyle)
    missing_cols = set(X_train_encoded.columns) - set(X_test_encoded.columns)
    for col in missing_cols:
        X_test_encoded[col] = 0
    
    # Test'te olup train'de olmayan sÃ¼tunlarÄ± kaldÄ±r
    extra_cols = set(X_test_encoded.columns) - set(X_train_encoded.columns)
    X_test_encoded = X_test_encoded.drop(columns=extra_cols)
    
    # SÃ¼tun sÄ±rasÄ±nÄ± aynÄ± yap
    X_test_encoded = X_test_encoded[X_train_encoded.columns]
    
    X_train = X_train_encoded
    X_test = X_test_encoded
    
    print(f"  - One-Hot Encoding tamamlandÄ±")
    print(f"  - Toplam {len(categorical_cols)} kategorik sÃ¼tun encode edildi")
    for col in categorical_cols:
        encoded_cols = [c for c in X_train.columns if c.startswith(f"{col}_")]
        print(f"  - {col}: {len(encoded_cols)} kategoriye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")

print(f"\nâœ“ Veri Ã¶n iÅŸleme tamamlandÄ±!")
print(f"âœ“ Train shape: {X_train.shape}")
print(f"âœ“ Test shape: {X_test.shape}")

# ============================================================================
# 3. DECISION TREE MODELÄ° OLUÅTURMA
# ============================================================================
print("\n[3] Decision Tree Modeli OluÅŸturma")
print("-"*70)

# Train-validation split
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y, test_size=0.2, random_state=42, stratify=y
)

print(f"âœ“ Train set: {X_train_split.shape[0]} Ã¶rnekleri")
print(f"âœ“ Validation set: {X_val_split.shape[0]} Ã¶rnekleri")

# Decision Tree modeli - BasitleÅŸtirilmiÅŸ parametreler (Random Forest ile karÅŸÄ±laÅŸtÄ±rma iÃ§in)
print("\nğŸŒ³ Decision Tree parametreleri (BasitleÅŸtirilmiÅŸ):")
print("  - max_depth: 5 (aÄŸacÄ±n maksimum derinliÄŸi - sÄ±nÄ±rlandÄ±rÄ±ldÄ±)")
print("  - min_samples_split: 100 (dallanma iÃ§in minimum Ã¶rnek sayÄ±sÄ±)")
print("  - min_samples_leaf: 50 (yaprak dÃ¼ÄŸÃ¼mdeki minimum Ã¶rnek sayÄ±sÄ±)")
print("  - criterion: gini (bÃ¶lÃ¼nme kriteri)")
print("  - random_state: 42")
print("  - class_weight: balanced (dengesiz veri iÃ§in)")

dt_model = DecisionTreeClassifier(
    max_depth=5,                    # Daha sÄ±ÄŸ aÄŸaÃ§ - overfitting Ã¶nleme
    min_samples_split=100,          # Daha fazla Ã¶rnek gerekli
    min_samples_leaf=50,            # Daha bÃ¼yÃ¼k yaprak dÃ¼ÄŸÃ¼mleri
    criterion='gini',               # Gini impurity kullan
    random_state=42,
    class_weight='balanced'         # Dengesiz veri iÃ§in sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±
)

print("\nâ³ Model eÄŸitiliyor...")
dt_model.fit(X_train_split, y_train_split)
print("âœ“ Model eÄŸitimi tamamlandÄ±!")

# Model bilgileri
print(f"\nğŸ“Š Model Ã–zellikleri:")
print(f"  - AÄŸaÃ§ derinliÄŸi: {dt_model.get_depth()}")
print(f"  - Yaprak sayÄ±sÄ±: {dt_model.get_n_leaves()}")
print(f"  - Toplam dÃ¼ÄŸÃ¼m sayÄ±sÄ±: {dt_model.tree_.node_count}")

# ============================================================================
# 4. MODEL DEÄERLENDÄ°RME
# ============================================================================
print("\n[4] Model DeÄŸerlendirme")
print("-"*70)

# Tahminler
y_train_pred = dt_model.predict(X_train_split)
y_val_pred = dt_model.predict(X_val_split)
y_train_proba = dt_model.predict_proba(X_train_split)[:, 1]
y_val_proba = dt_model.predict_proba(X_val_split)[:, 1]

# Metrikler
print("\nğŸ“ˆ PERFORMANS METRÄ°KLERÄ°")
print("="*70)

print("\nğŸ”¹ Train Seti:")
print(f"  â€¢ Accuracy:  {accuracy_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ Precision: {precision_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ Recall:    {recall_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ F1-Score:  {f1_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ ROC-AUC:   {roc_auc_score(y_train_split, y_train_proba):.4f}")

print("\nğŸ”¹ Validation Seti:")
print(f"  â€¢ Accuracy:  {accuracy_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ Precision: {precision_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ Recall:    {recall_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ F1-Score:  {f1_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ ROC-AUC:   {roc_auc_score(y_val_split, y_val_proba):.4f}")

# Classification Report
print("\nğŸ“‹ DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu (Validation):")
print("-"*70)
print(classification_report(y_val_split, y_val_pred, 
                          target_names=['Not Leave (0)', 'Leave (1)']))

# Confusion Matrix
cm = confusion_matrix(y_val_split, y_val_pred)
print("\nğŸ”¢ Confusion Matrix (Validation):")
print(cm)
print(f"  True Negatives:  {cm[0, 0]}")
print(f"  False Positives: {cm[0, 1]}")
print(f"  False Negatives: {cm[1, 0]}")
print(f"  True Positives:  {cm[1, 1]}")

# Feature Importance
print("\nâ­ En Ã–nemli Ã–zellikler (Top 10):")
print("-"*70)
feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': dt_model.feature_importances_
}).sort_values('Importance', ascending=False)

for idx, row in feature_importance.head(10).iterrows():
    print(f"  {row['Feature']:30s} : {row['Importance']:.4f}")

# ============================================================================
# 5. GÃ–RSELLEÅTÄ°RME
# ============================================================================
print("\n[5] GÃ¶rselleÅŸtirmeler OluÅŸturuluyor...")
print("-"*70)

# outputs/decision_tree klasÃ¶rÃ¼nÃ¼ oluÅŸtur
os.makedirs('../outputs/decision_tree', exist_ok=True)

# outputs klasÃ¶rÃ¼nÃ¼ oluÅŸtur
import os
os.makedirs('../outputs', exist_ok=True)

# Figure oluÅŸtur - BirleÅŸik gÃ¶rsel
fig = plt.figure(figsize=(20, 12))

# 1. Confusion Matrix
ax1 = plt.subplot(2, 3, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')

# 2. Feature Importance
ax2 = plt.subplot(2, 3, 2)
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#c0392b', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=9, fontweight='bold')
plt.gca().invert_yaxis()

# 3. ROC Curve
ax3 = plt.subplot(2, 3, 3)
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#c0392b')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. Target Distribution
ax4 = plt.subplot(2, 3, 4)
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')

# 5. Accuracy Comparison
ax5 = plt.subplot(2, 3, 5)
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#e74c3c', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#c0392b', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')

# 6. Decision Tree yapÄ±sÄ±nÄ± gÃ¶ster (basitleÅŸtirilmiÅŸ)
ax6 = plt.subplot(2, 3, 6)
plot_tree(dt_model, 
          max_depth=3,  # GÃ¶rselleÅŸtirme iÃ§in ilk 3 seviye
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=7,
          rounded=True)
plt.title('Decision Tree YapÄ±sÄ± (Ä°lk 3 Seviye)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.savefig('../outputs/decision_tree/decision_tree_analysis.png', dpi=300, bbox_inches='tight')
print("âœ“ BirleÅŸik grafik kaydedildi: outputs/decision_tree/decision_tree_analysis.png")

# ============================================================================
# AYRI AYRI GRAFÄ°KLER
# ============================================================================
print("\nğŸ“Š Grafikleri ayrÄ± ayrÄ± kaydediyorum...")

# 1. Confusion Matrix - AyrÄ±
fig1 = plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Confusion Matrix kaydedildi")

# 2. Feature Importance - AyrÄ±
fig2 = plt.figure(figsize=(10, 8))
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#c0392b', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=10, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Feature Importance kaydedildi")

# 3. ROC Curve - AyrÄ±
fig3 = plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#c0392b')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_roc_curve.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ ROC Curve kaydedildi")

# 4. Target Distribution - AyrÄ±
fig4 = plt.figure(figsize=(8, 6))
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_target_distribution.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Target Distribution kaydedildi")

# 5. Performance Metrics - AyrÄ±
fig5 = plt.figure(figsize=(10, 6))
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#e74c3c', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#c0392b', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_performance_metrics.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Performance Metrics kaydedildi")

# 6. Tree Structure (simplified) - AyrÄ±
fig6 = plt.figure(figsize=(20, 12))
plot_tree(dt_model, 
          max_depth=3,
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=9,
          rounded=True)
plt.title('Decision Tree YapÄ±sÄ± (Ä°lk 3 Seviye)', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('../outputs/decision_tree/dt_tree_structure_simple.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Tree Structure (simplified) kaydedildi")

# Daha detaylÄ± aÄŸaÃ§ gÃ¶rselleÅŸtirmesi
fig7 = plt.figure(figsize=(25, 15))
plot_tree(dt_model, 
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=10,
          rounded=True,
          proportion=True)
plt.title('Decision Tree - Tam YapÄ±', fontsize=16, fontweight='bold', pad=20)
plt.savefig('../outputs/decision_tree/decision_tree_full.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Tam aÄŸaÃ§ gÃ¶rselleÅŸtirmesi kaydedildi")

print("\nâœ“ TÃ¼m grafikler hem birleÅŸik hem de ayrÄ± ayrÄ± kaydedildi!")

# ============================================================================
# 6. TEST VERÄ°SÄ° Ä°Ã‡Ä°N TAHMÄ°NLER
# ============================================================================
print("\n[6] Test Verisi Tahminleri")
print("-"*70)

# TÃ¼m train verisi ile son modeli eÄŸit
print("â³ Final model tÃ¼m train verisi ile eÄŸitiliyor...")
final_model = DecisionTreeClassifier(
    max_depth=7,
    min_samples_split=50,
    min_samples_leaf=25,
    criterion='gini',
    random_state=42,
    class_weight='balanced'
)
final_model.fit(X_train, y)
print("âœ“ Final model eÄŸitimi tamamlandÄ±!")

# Test tahminleri
test_predictions = final_model.predict_proba(X_test)[:, 1]

# Submission dosyasÄ±nÄ± hazÄ±rla
os.makedirs('../submissions', exist_ok=True)
submission['target'] = test_predictions
submission.to_csv('../submissions/submission_decision_tree.csv', index=False)
print(f"âœ“ Submission dosyasÄ± oluÅŸturuldu: submissions/submission_decision_tree.csv")
print(f"âœ“ Tahmin edilen test Ã¶rnekleri: {len(test_predictions)}")
print(f"\nTahmin Ä°statistikleri:")
print(f"  â€¢ Ortalama: {test_predictions.mean():.4f}")
print(f"  â€¢ Std:      {test_predictions.std():.4f}")
print(f"  â€¢ Min:      {test_predictions.min():.4f}")
print(f"  â€¢ Max:      {test_predictions.max():.4f}")

# ============================================================================
# Ã–ZET
# ============================================================================
print("\n" + "="*70)
print("MODEL Ã–ZETI")
print("="*70)
print(f"\nâœ“ Model Tipi: Decision Tree Classifier")
print(f"âœ“ AÄŸaÃ§ DerinliÄŸi: {final_model.get_depth()}")
print(f"âœ“ Yaprak SayÄ±sÄ±: {final_model.get_n_leaves()}")
print(f"âœ“ Validation Accuracy: {accuracy_score(y_val_split, y_val_pred):.4f}")
print(f"âœ“ Validation ROC-AUC: {roc_auc_score(y_val_split, y_val_proba):.4f}")
print(f"\nğŸ“ OluÅŸturulan Dosyalar:")
print(f"  BirleÅŸik GÃ¶rsel:")
print(f"    â€¢ outputs/decision_tree_analysis.png - Genel analiz grafikleri")
print(f"  AyrÄ± GÃ¶rseller:")
print(f"    â€¢ outputs/dt_confusion_matrix.png")
print(f"    â€¢ outputs/dt_feature_importance.png")
print(f"    â€¢ outputs/dt_roc_curve.png")
print(f"    â€¢ outputs/dt_target_distribution.png")
print(f"    â€¢ outputs/dt_performance_metrics.png")
print(f"    â€¢ outputs/dt_tree_structure_simple.png")
print(f"    â€¢ outputs/decision_tree_full.png")
print(f"  Submission:")
print(f"    â€¢ submissions/submission_decision_tree.csv")

print("\n" + "="*70)
print("âœ… Ä°ÅLEM TAMAMLANDI!")
print("="*70)
print("\nğŸ’¡ Not: Decision Tree basit ve yorumlanabilir bir modeldir.")
print("   Random Forest ile karÅŸÄ±laÅŸtÄ±rma yapmak iÃ§in birden fazla")
print("   aÄŸacÄ±n ensemble'Ä±nÄ± kullanmanÄ±z gerekecek.")
print("="*70)
