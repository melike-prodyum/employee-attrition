"""
Employee Attrition Prediction - Random Forest Model
Ã‡alÄ±ÅŸan iÅŸten ayrÄ±lma tahmini iÃ§in Random Forest modeli
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import plot_tree
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve
)
import warnings
warnings.filterwarnings('ignore')

# GÃ¶rselleÅŸtirme ayarlarÄ±
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*70)
print("EMPLOYEE ATTRITION PREDICTION - RANDOM FOREST MODEL")
print("="*70)

# ============================================================================
# 1. VERÄ° YÃœKLEME VE KEÅÄ°F ANALÄ°ZÄ°
# ============================================================================
print("\n[1] Veri YÃ¼kleme ve KeÅŸif Analizi")
print("-"*70)

# Veri setlerini yÃ¼kle
import os
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
train_df = pd.read_csv(os.path.join(project_root, 'data', 'aug_train.csv'))
test_df = pd.read_csv(os.path.join(project_root, 'data', 'aug_test.csv'))
submission = pd.read_csv(os.path.join(project_root, 'data', 'sample_submission.csv'))

print(f"âœ“ Train veri seti boyutu: {train_df.shape}")
print(f"âœ“ Test veri seti boyutu: {test_df.shape}")
print(f"\nSÃ¼tunlar: {list(train_df.columns)}")

# Target daÄŸÄ±lÄ±mÄ±
print(f"\nğŸ“Š Target DaÄŸÄ±lÄ±mÄ±:")
print(train_df['target'].value_counts())
print(f"Target oranÄ±: {train_df['target'].value_counts(normalize=True)}")

# Eksik deÄŸerler
print(f"\nğŸ“‹ Eksik DeÄŸerler:")
missing = train_df.isnull().sum()
missing_pct = (missing / len(train_df)) * 100
missing_df = pd.DataFrame({
    'Eksik SayÄ±sÄ±': missing,
    'YÃ¼zde': missing_pct
}).sort_values('Eksik SayÄ±sÄ±', ascending=False)
print(missing_df[missing_df['Eksik SayÄ±sÄ±'] > 0])

# ============================================================================
# 2. VERÄ° Ã–N Ä°ÅLEME
# ============================================================================
print("\n[2] Veri Ã–n Ä°ÅŸleme")
print("-"*70)

# enrollee_id'yi ayÄ±r
train_ids = train_df['enrollee_id']
test_ids = test_df['enrollee_id']

# Target deÄŸiÅŸkeni ayÄ±r
y = train_df['target']
X_train = train_df.drop(['enrollee_id', 'target'], axis=1)
X_test = test_df.drop(['enrollee_id'], axis=1)

print(f"âœ“ Feature sayÄ±sÄ±: {X_train.shape[1]}")

# Kategorik ve numerik sÃ¼tunlarÄ± ayÄ±r
categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()
numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()

print(f"âœ“ Kategorik sÃ¼tunlar ({len(categorical_cols)}): {categorical_cols}")
print(f"âœ“ Numerik sÃ¼tunlar ({len(numerical_cols)}): {numerical_cols}")

# Eksik deÄŸerleri doldur
print("\nğŸ”§ Eksik deÄŸerleri doldurma:")

# Numerik sÃ¼tunlar iÃ§in median
for col in numerical_cols:
    if X_train[col].isnull().sum() > 0:
        median_val = X_train[col].median()
        X_train[col].fillna(median_val, inplace=True)
        X_test[col].fillna(median_val, inplace=True)
        print(f"  - {col}: median ile dolduruldu")

# Kategorik sÃ¼tunlar iÃ§in mode
for col in categorical_cols:
    if X_train[col].isnull().sum() > 0:
        mode_val = X_train[col].mode()[0] if not X_train[col].mode().empty else 'Unknown'
        X_train[col].fillna(mode_val, inplace=True)
        X_test[col].fillna(mode_val, inplace=True)
        print(f"  - {col}: mode ile dolduruldu")

# Kategorik deÄŸiÅŸkenleri encode et
print("\nğŸ”§ Kategorik deÄŸiÅŸkenleri encode etme:")
label_encoders = {}

for col in categorical_cols:
    le = LabelEncoder()
    # Train ve test'i birleÅŸtirerek tÃ¼m kategorileri Ã¶ÄŸren
    combined = pd.concat([X_train[col], X_test[col]], axis=0)
    le.fit(combined)
    
    X_train[col] = le.transform(X_train[col])
    X_test[col] = le.transform(X_test[col])
    label_encoders[col] = le
    print(f"  - {col}: {len(le.classes_)} kategori")

print(f"\nâœ“ Veri Ã¶n iÅŸleme tamamlandÄ±!")
print(f"âœ“ Train shape: {X_train.shape}")
print(f"âœ“ Test shape: {X_test.shape}")

# ============================================================================
# 3. RANDOM FOREST MODELÄ° OLUÅTURMA
# ============================================================================
print("\n[3] Random Forest Modeli OluÅŸturma")
print("-"*70)

# Train-validation split
X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
    X_train, y, test_size=0.2, random_state=42, stratify=y
)

print(f"âœ“ Train set: {X_train_split.shape[0]} Ã¶rnekleri")
print(f"âœ“ Validation set: {X_val_split.shape[0]} Ã¶rnekleri")

# Random Forest modeli - Her aÄŸaÃ§ basit ama birÃ§ok aÄŸaÃ§
print("\nğŸŒ² Random Forest parametreleri:")
print("  - n_estimators: 100 (100 farklÄ± decision tree)")
print("  - max_depth: 4 (her aÄŸacÄ±n maksimum derinliÄŸi - basit)")
print("  - min_samples_split: 200 (dallanma iÃ§in minimum Ã¶rnek)")
print("  - min_samples_leaf: 100 (yaprak dÃ¼ÄŸÃ¼mdeki minimum Ã¶rnek)")
print("  - criterion: gini (bÃ¶lÃ¼nme kriteri)")
print("  - random_state: 42")
print("  - n_jobs: -1 (paralel iÅŸleme)")

rf_model = RandomForestClassifier(
    n_estimators=100,               # 100 aÄŸaÃ§ oluÅŸtur
    max_depth=4,                    # Her aÄŸaÃ§ basit olsun (4 seviye)
    min_samples_split=200,          # Dallanma iÃ§in gereken minimum Ã¶rnek
    min_samples_leaf=100,           # Her yaprakta en az bu kadar Ã¶rnek
    criterion='gini',               # Gini impurity kullan
    random_state=42,
    class_weight='balanced',        # Dengesiz veri iÃ§in sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ±
    n_jobs=-1,                      # TÃ¼m CPU core'larÄ± kullan
    max_features='sqrt'             # Her dallanmada rastgele feature seÃ§
)

print("\nâ³ Random Forest eÄŸitiliyor (100 aÄŸaÃ§)...")
rf_model.fit(X_train_split, y_train_split)
print("âœ“ Model eÄŸitimi tamamlandÄ±!")

# Model bilgileri
print(f"\nğŸ“Š Model Ã–zellikleri:")
print(f"  - AÄŸaÃ§ sayÄ±sÄ±: {rf_model.n_estimators}")
print(f"  - Her aÄŸaÃ§ iÃ§in max derinlik: {rf_model.max_depth}")
print(f"  - Toplam estimator: {len(rf_model.estimators_)}")

# Ä°lk birkaÃ§ aÄŸacÄ±n derinliÄŸini gÃ¶ster
tree_depths = [tree.get_depth() for tree in rf_model.estimators_[:5]]
print(f"  - Ä°lk 5 aÄŸacÄ±n derinlikleri: {tree_depths}")

# ============================================================================
# 4. MODEL DEÄERLENDÄ°RME
# ============================================================================
print("\n[4] Model DeÄŸerlendirme")
print("-"*70)

# Tahminler
y_train_pred = rf_model.predict(X_train_split)
y_val_pred = rf_model.predict(X_val_split)
y_train_proba = rf_model.predict_proba(X_train_split)[:, 1]
y_val_proba = rf_model.predict_proba(X_val_split)[:, 1]

# Metrikler
print("\nğŸ“ˆ PERFORMANS METRÄ°KLERÄ°")
print("="*70)

print("\nğŸ”¹ Train Seti:")
print(f"  â€¢ Accuracy:  {accuracy_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ Precision: {precision_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ Recall:    {recall_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ F1-Score:  {f1_score(y_train_split, y_train_pred):.4f}")
print(f"  â€¢ ROC-AUC:   {roc_auc_score(y_train_split, y_train_proba):.4f}")

print("\nğŸ”¹ Validation Seti:")
print(f"  â€¢ Accuracy:  {accuracy_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ Precision: {precision_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ Recall:    {recall_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ F1-Score:  {f1_score(y_val_split, y_val_pred):.4f}")
print(f"  â€¢ ROC-AUC:   {roc_auc_score(y_val_split, y_val_proba):.4f}")

# Classification Report
print("\nğŸ“‹ DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu (Validation):")
print("-"*70)
print(classification_report(y_val_split, y_val_pred, 
                          target_names=['Not Leave (0)', 'Leave (1)']))

# Confusion Matrix
cm = confusion_matrix(y_val_split, y_val_pred)
print("\nğŸ”¢ Confusion Matrix (Validation):")
print(cm)
print(f"  True Negatives:  {cm[0, 0]}")
print(f"  False Positives: {cm[0, 1]}")
print(f"  False Negatives: {cm[1, 0]}")
print(f"  True Positives:  {cm[1, 1]}")

# Feature Importance
print("\nâ­ En Ã–nemli Ã–zellikler (Top 10):")
print("-"*70)
feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

for idx, row in feature_importance.head(10).iterrows():
    print(f"  {row['Feature']:30s} : {row['Importance']:.4f}")

# ============================================================================
# 5. GÃ–RSELLEÅTÄ°RME
# ============================================================================
print("\n[5] GÃ¶rselleÅŸtirmeler OluÅŸturuluyor...")
print("-"*70)

# outputs/random_forest klasÃ¶rÃ¼nÃ¼ oluÅŸtur
import os
os.makedirs('../outputs/random_forest', exist_ok=True)

# Figure oluÅŸtur - BirleÅŸik gÃ¶rsel
fig = plt.figure(figsize=(20, 14))

# 1. Confusion Matrix
ax1 = plt.subplot(3, 3, 1)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')

# 2. Feature Importance
ax2 = plt.subplot(3, 3, 2)
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#27ae60', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=9, fontweight='bold')
plt.gca().invert_yaxis()

# 3. ROC Curve
ax3 = plt.subplot(3, 3, 3)
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#27ae60')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)

# 4. Target Distribution
ax4 = plt.subplot(3, 3, 4)
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')

# 5. Accuracy Comparison
ax5 = plt.subplot(3, 3, 5)
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#2ecc71', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#27ae60', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')

# 6-9. Ä°lk 4 aÄŸacÄ±n gÃ¶rselleÅŸtirmesi
print("âœ“ Ä°lk 4 aÄŸacÄ± gÃ¶rselleÅŸtiriyorum...")
for i in range(4):
    ax = plt.subplot(3, 3, 6 + i)
    plot_tree(rf_model.estimators_[i], 
              max_depth=2,  # Sadece ilk 2 seviye gÃ¶ster
              filled=True, 
              feature_names=X_train.columns,
              class_names=['Not Leave', 'Leave'],
              fontsize=7,
              rounded=True)
    plt.title(f'AÄŸaÃ§ #{i+1} (Ä°lk 2 Seviye)', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.savefig('../outputs/random_forest/random_forest_analysis.png', dpi=300, bbox_inches='tight')
print("âœ“ BirleÅŸik grafik kaydedildi: outputs/random_forest/random_forest_analysis.png")

# ============================================================================
# AYRI AYRI GRAFÄ°KLER
# ============================================================================
print("\nğŸ“Š Grafikleri ayrÄ± ayrÄ± kaydediyorum...")

# 1. Confusion Matrix - AyrÄ±
fig1 = plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False,
            xticklabels=['Not Leave', 'Leave'],
            yticklabels=['Not Leave', 'Leave'])
plt.title('Confusion Matrix (Validation)', fontsize=14, fontweight='bold')
plt.ylabel('GerÃ§ek DeÄŸer')
plt.xlabel('Tahmin')
plt.tight_layout()
plt.savefig('../outputs/random_forest/rf_confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Confusion Matrix kaydedildi")

# 2. Feature Importance - AyrÄ±
fig2 = plt.figure(figsize=(10, 8))
top_features = feature_importance.head(10)
bars = plt.barh(range(len(top_features)), top_features['Importance'], color='#27ae60', alpha=0.7)
plt.yticks(range(len(top_features)), top_features['Feature'])
plt.xlabel('Importance')
plt.title('Top 10 Ã–nemli Ã–zellikler', fontsize=14, fontweight='bold')
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (idx, row) in enumerate(top_features.iterrows()):
    plt.text(row['Importance'], i, f' {row["Importance"]:.4f}', 
             va='center', fontsize=10, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('../outputs/random_forest/rf_feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Feature Importance kaydedildi")

# 3. ROC Curve - AyrÄ±
fig3 = plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(y_val_split, y_val_proba)
plt.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {roc_auc_score(y_val_split, y_val_proba):.4f})', color='#27ae60')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('../outputs/random_forest/rf_roc_curve.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ ROC Curve kaydedildi")

# 4. Target Distribution - AyrÄ±
fig4 = plt.figure(figsize=(8, 6))
target_counts = y.value_counts()
plt.bar(['Not Leave (0)', 'Leave (1)'], target_counts.values, color=['#3498db', '#e74c3c'])
plt.title('Target DaÄŸÄ±lÄ±mÄ± (Train)', fontsize=14, fontweight='bold')
plt.ylabel('SayÄ±')
for i, v in enumerate(target_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')
plt.tight_layout()
plt.savefig('../outputs/random_forest/rf_target_distribution.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Target Distribution kaydedildi")

# 5. Performance Metrics - AyrÄ±
fig5 = plt.figure(figsize=(10, 6))
metrics_train = [
    accuracy_score(y_train_split, y_train_pred),
    precision_score(y_train_split, y_train_pred),
    recall_score(y_train_split, y_train_pred),
    f1_score(y_train_split, y_train_pred)
]
metrics_val = [
    accuracy_score(y_val_split, y_val_pred),
    precision_score(y_val_split, y_val_pred),
    recall_score(y_val_split, y_val_pred),
    f1_score(y_val_split, y_val_pred)
]
x = np.arange(4)
width = 0.35
bars1 = plt.bar(x - width/2, metrics_train, width, label='Train', color='#2ecc71', alpha=0.7)
bars2 = plt.bar(x + width/2, metrics_val, width, label='Validation', color='#27ae60', alpha=0.9)
# DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine ekle
for i, (v1, v2) in enumerate(zip(metrics_train, metrics_val)):
    plt.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    plt.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
plt.xlabel('Metrikler')
plt.ylabel('Skor')
plt.title('Model PerformansÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14, fontweight='bold')
plt.xticks(x, ['Accuracy', 'Precision', 'Recall', 'F1-Score'], rotation=45)
plt.legend()
plt.ylim([0, 1.1])
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('../outputs/random_forest/rf_performance_metrics.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Performance Metrics kaydedildi")

# 6. Ä°lk 4 aÄŸaÃ§ - AyrÄ± ayrÄ±
for i in range(4):
    fig_tree = plt.figure(figsize=(12, 8))
    plot_tree(rf_model.estimators_[i], 
              max_depth=2,
              filled=True, 
              feature_names=X_train.columns,
              class_names=['Not Leave', 'Leave'],
              fontsize=9,
              rounded=True)
    plt.title(f'Random Forest - AÄŸaÃ§ #{i+1} (Ä°lk 2 Seviye)', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(f'../outputs/random_forest/rf_tree_{i+1}.png', dpi=300, bbox_inches='tight')
    plt.close()
print(f"  âœ“ Ä°lk 4 aÄŸaÃ§ ayrÄ± ayrÄ± kaydedildi")

# Tek bir aÄŸacÄ±n tam yapÄ±sÄ±
print("âœ“ Ä°lk aÄŸacÄ±n tam yapÄ±sÄ±nÄ± kaydediyorum...")
fig_full = plt.figure(figsize=(25, 15))
plot_tree(rf_model.estimators_[0], 
          filled=True, 
          feature_names=X_train.columns,
          class_names=['Not Leave', 'Leave'],
          fontsize=10,
          rounded=True,
          proportion=True)
plt.title('Random Forest - Ä°lk AÄŸaÃ§ (Tam YapÄ±)', fontsize=16, fontweight='bold', pad=20)
plt.savefig('../outputs/random_forest/random_forest_single_tree.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ Tek aÄŸaÃ§ gÃ¶rselleÅŸtirmesi kaydedildi")

# AÄŸaÃ§ derinlikleri daÄŸÄ±lÄ±mÄ±
fig_stats = plt.figure(figsize=(12, 6))

# Sol: AÄŸaÃ§ derinlikleri
ax1 = plt.subplot(1, 2, 1)
all_depths = [tree.get_depth() for tree in rf_model.estimators_]
plt.hist(all_depths, bins=range(min(all_depths), max(all_depths) + 2), 
         color='#27ae60', alpha=0.7, edgecolor='black')
plt.xlabel('AÄŸaÃ§ DerinliÄŸi', fontweight='bold')
plt.ylabel('AÄŸaÃ§ SayÄ±sÄ±', fontweight='bold')
plt.title('100 AÄŸacÄ±n Derinlik DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')
plt.axvline(np.mean(all_depths), color='red', linestyle='--', 
            label=f'Ortalama: {np.mean(all_depths):.2f}')
plt.legend()
plt.grid(True, alpha=0.3)

# SaÄŸ: Yaprak sayÄ±larÄ±
ax2 = plt.subplot(1, 2, 2)
all_leaves = [tree.get_n_leaves() for tree in rf_model.estimators_]
plt.hist(all_leaves, bins=20, color='#2ecc71', alpha=0.7, edgecolor='black')
plt.xlabel('Yaprak SayÄ±sÄ±', fontweight='bold')
plt.ylabel('AÄŸaÃ§ SayÄ±sÄ±', fontweight='bold')
plt.title('100 AÄŸacÄ±n Yaprak SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')
plt.axvline(np.mean(all_leaves), color='red', linestyle='--', 
            label=f'Ortalama: {np.mean(all_leaves):.2f}')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('../outputs/random_forest/random_forest_tree_stats.png', dpi=300, bbox_inches='tight')
plt.close()
print("  âœ“ AÄŸaÃ§ istatistikleri kaydedildi")

print("\nâœ“ TÃ¼m grafikler hem birleÅŸik hem de ayrÄ± ayrÄ± kaydedildi!")


# ============================================================================
# 6. TEST VERÄ°SÄ° Ä°Ã‡Ä°N TAHMÄ°NLER
# ============================================================================
print("\n[6] Test Verisi Tahminleri")
print("-"*70)

# TÃ¼m train verisi ile son modeli eÄŸit
print("â³ Final Random Forest modeli tÃ¼m train verisi ile eÄŸitiliyor...")
final_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=4,
    min_samples_split=200,
    min_samples_leaf=100,
    criterion='gini',
    random_state=42,
    class_weight='balanced',
    n_jobs=-1,
    max_features='sqrt'
)
final_model.fit(X_train, y)
print("âœ“ Final model eÄŸitimi tamamlandÄ±!")

# Test tahminleri
test_predictions = final_model.predict_proba(X_test)[:, 1]

# Submission dosyasÄ±nÄ± hazÄ±rla
os.makedirs('../submissions', exist_ok=True)
submission['target'] = test_predictions
submission.to_csv('../submissions/submission_random_forest.csv', index=False)
print(f"âœ“ Submission dosyasÄ± oluÅŸturuldu: submissions/submission_random_forest.csv")
print(f"âœ“ Tahmin edilen test Ã¶rnekleri: {len(test_predictions)}")
print(f"\nTahmin Ä°statistikleri:")
print(f"  â€¢ Ortalama: {test_predictions.mean():.4f}")
print(f"  â€¢ Std:      {test_predictions.std():.4f}")
print(f"  â€¢ Min:      {test_predictions.min():.4f}")
print(f"  â€¢ Max:      {test_predictions.max():.4f}")

# ============================================================================
# Ã–ZET
# ============================================================================
print("\n" + "="*70)
print("MODEL Ã–ZETI")
print("="*70)
print(f"\nâœ“ Model Tipi: Random Forest Classifier")
print(f"âœ“ Toplam AÄŸaÃ§ SayÄ±sÄ±: {final_model.n_estimators}")
print(f"âœ“ Her AÄŸaÃ§ DerinliÄŸi: {final_model.max_depth}")
print(f"âœ“ Ortalama AÄŸaÃ§ DerinliÄŸi: {np.mean([tree.get_depth() for tree in final_model.estimators_]):.2f}")
print(f"âœ“ Ortalama Yaprak SayÄ±sÄ±: {np.mean([tree.get_n_leaves() for tree in final_model.estimators_]):.2f}")
print(f"âœ“ Validation Accuracy: {accuracy_score(y_val_split, y_val_pred):.4f}")
print(f"âœ“ Validation ROC-AUC: {roc_auc_score(y_val_split, y_val_proba):.4f}")
print(f"\nğŸ“ OluÅŸturulan Dosyalar:")
print(f"  BirleÅŸik GÃ¶rsel:")
print(f"    â€¢ outputs/random_forest_analysis.png - Genel analiz grafikleri")
print(f"  AyrÄ± GÃ¶rseller:")
print(f"    â€¢ outputs/rf_confusion_matrix.png")
print(f"    â€¢ outputs/rf_feature_importance.png")
print(f"    â€¢ outputs/rf_roc_curve.png")
print(f"    â€¢ outputs/rf_target_distribution.png")
print(f"    â€¢ outputs/rf_performance_metrics.png")
print(f"    â€¢ outputs/rf_tree_1.png, rf_tree_2.png, rf_tree_3.png, rf_tree_4.png")
print(f"    â€¢ outputs/random_forest_single_tree.png - Tek aÄŸaÃ§ tam yapÄ±sÄ±")
print(f"    â€¢ outputs/random_forest_tree_stats.png - AÄŸaÃ§ istatistikleri")
print(f"  Submission:")
print(f"    â€¢ submissions/submission_random_forest.csv")

print("\n" + "="*70)
print("âœ… Ä°ÅLEM TAMAMLANDI!")
print("="*70)
print("\nğŸ’¡ Random Forest Ã–zellikleri:")
print("   â€¢ 100 farklÄ± decision tree kullanÄ±r (ensemble)")
print("   â€¢ Her aÄŸaÃ§ farklÄ± veri Ã¶rnekleriyle eÄŸitilir (bootstrap)")
print("   â€¢ Her dallanmada rastgele feature seÃ§imi yapar")
print("   â€¢ Final tahmin = TÃ¼m aÄŸaÃ§larÄ±n ortalamasÄ±")
print("   â€¢ Tek aÄŸaÃ§tan daha gÃ¼Ã§lÃ¼ ve robust")
print("="*70)
