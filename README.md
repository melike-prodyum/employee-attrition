# Employee Attrition Prediction
## Ã‡alÄ±ÅŸan Ä°ÅŸten AyrÄ±lma Tahmini - Machine Learning Projesi

Bu proje, Ã§alÄ±ÅŸanlarÄ±n iÅŸten ayrÄ±lma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmek iÃ§in **Decision Tree** ve **Random Forest** makine Ã¶ÄŸrenmesi modellerini kullanÄ±r ve bu iki yÃ¶ntem arasÄ±ndaki farklarÄ± gÃ¶sterir.

---

## ğŸ“Š Veri Seti

- **aug_train.csv**: 19,158 eÄŸitim Ã¶rneÄŸi
- **aug_test.csv**: 2,129 test Ã¶rneÄŸi
- **Ã–zellikler**: 12 feature (ÅŸehir, deneyim, eÄŸitim, ÅŸirket bilgileri vb.)
- **Hedef**: Binary sÄ±nÄ±flandÄ±rma (0: Kalmaya devam, 1: Ä°ÅŸten ayrÄ±lacak)

### Veri Ã–zellikleri:
- `city`: Åehir kodu
- `city_development_index`: Åehir geliÅŸmiÅŸlik endeksi
- `gender`: Cinsiyet
- `relevent_experience`: Ä°lgili deneyim durumu
- `enrolled_university`: Ãœniversite kayÄ±t durumu
- `education_level`: EÄŸitim seviyesi
- `major_discipline`: Ana disiplin
- `experience`: Toplam deneyim yÄ±lÄ±
- `company_size`: Åirket bÃ¼yÃ¼klÃ¼ÄŸÃ¼
- `company_type`: Åirket tipi
- `last_new_job`: Son iÅŸ deÄŸiÅŸikliÄŸi
- `training_hours`: EÄŸitim saatleri

---

## ğŸš€ KullanÄ±m

### 1. Decision Tree Modeli
```bash
python decision_tree_model.py
```

**Ã‡Ä±ktÄ±lar:**
- `decision_tree_analysis.png` - Genel analiz grafikleri
- `decision_tree_full.png` - Tam aÄŸaÃ§ yapÄ±sÄ±
- `submission_decision_tree.csv` - Test tahminleri

### 2. Model KarÅŸÄ±laÅŸtÄ±rmasÄ± (Decision Tree vs Random Forest)
```bash
python compare_models.py
```

**Ã‡Ä±ktÄ±lar:**
- `model_comparison.png` - KarÅŸÄ±laÅŸtÄ±rma grafikleri
- `submission_random_forest.csv` - Random Forest tahminleri

---

## ğŸ“ˆ Model PerformanslarÄ±

### Decision Tree (Validation Set)
| Metrik | DeÄŸer |
|--------|-------|
| **Accuracy** | 0.6806 |
| **Precision** | 0.4253 |
| **Recall** | 0.8021 |
| **F1-Score** | 0.5559 |
| **ROC-AUC** | 0.7823 |

**Model Ã–zellikleri:**
- AÄŸaÃ§ DerinliÄŸi: 6
- Yaprak SayÄ±sÄ±: 40
- Tek aÄŸaÃ§ kullanÄ±r
- Yorumlanabilir

### Random Forest (Validation Set)
| Metrik | DeÄŸer |
|--------|-------|
| **Accuracy** | 0.7657 |
| **Precision** | 0.5231 |
| **Recall** | 0.6754 |
| **F1-Score** | 0.5896 |
| **ROC-AUC** | 0.7956 |

**Model Ã–zellikleri:**
- AÄŸaÃ§ SayÄ±sÄ±: 100
- Her aÄŸaÃ§ derinliÄŸi: 6
- Ensemble metodu
- Daha robust

### Ä°yileÅŸmeler (Random Forest)
- **Accuracy**: +12.50% â†‘
- **Precision**: +22.99% â†‘
- **Recall**: -15.80% â†“
- **F1-Score**: +6.06% â†‘
- **ROC-AUC**: +1.70% â†‘

---

## ğŸŒ³ Decision Tree vs ğŸŒ² Random Forest

### Decision Tree
âœ… **Avantajlar:**
- Yorumlanabilir ve anlaÅŸÄ±lÄ±r
- HÄ±zlÄ± eÄŸitim
- Tek model, basit
- GÃ¶rselleÅŸtirilebilir

âŒ **Dezavantajlar:**
- Overfitting riski yÃ¼ksek
- KÃ¼Ã§Ã¼k veri deÄŸiÅŸikliklerinde kararsÄ±z
- DÃ¼ÅŸÃ¼k genelleme

### Random Forest
âœ… **Avantajlar:**
- YÃ¼ksek doÄŸruluk
- Overfitting riski dÃ¼ÅŸÃ¼k
- Robust ve kararlÄ±
- Feature importance gÃ¼venilir

âŒ **Dezavantajlar:**
- YorumlanmasÄ± zor
- YavaÅŸ eÄŸitim
- Daha fazla kaynak gerekir
- Black-box model

---

## ğŸ” Temel Farklar

| Ã–zellik | Decision Tree | Random Forest |
|---------|---------------|---------------|
| AÄŸaÃ§ SayÄ±sÄ± | 1 | 100 |
| Veri Ã–rnekleme | TÃ¼m veri | Bootstrap sampling |
| Feature SeÃ§imi | TÃ¼m features | Rastgele subset |
| Tahmin | Tek aÄŸaÃ§ | AÄŸaÃ§larÄ±n ortalamasÄ± |
| Yorumlanabilirlik | YÃ¼ksek | DÃ¼ÅŸÃ¼k |
| DoÄŸruluk | DÃ¼ÅŸÃ¼k | YÃ¼ksek |

---

## ğŸ“Š En Ã–nemli Ã–zellikler

1. **city_development_index** (0.5853) - Åehir geliÅŸmiÅŸlik endeksi
2. **company_size** (0.2269) - Åirket bÃ¼yÃ¼klÃ¼ÄŸÃ¼
3. **education_level** (0.0511) - EÄŸitim seviyesi
4. **relevent_experience** (0.0511) - Ä°lgili deneyim
5. **city** (0.0351) - Åehir

---

## ğŸ› ï¸ Teknolojiler

- **Python 3.13**
- **pandas** - Veri manipÃ¼lasyonu
- **numpy** - SayÄ±sal hesaplamalar
- **scikit-learn** - Machine learning modelleri
- **matplotlib** - GÃ¶rselleÅŸtirme
- **seaborn** - Ä°statistiksel gÃ¶rselleÅŸtirme

---

## ğŸ“ Veri Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

1. **Eksik DeÄŸer Doldurma:**
   - Numerik deÄŸiÅŸkenler â†’ Median
   - Kategorik deÄŸiÅŸkenler â†’ Mode (en sÄ±k gÃ¶rÃ¼len)

2. **Encoding:**
   - Label Encoding (tÃ¼m kategorik deÄŸiÅŸkenler iÃ§in)

3. **Train-Validation Split:**
   - 80% Train, 20% Validation
   - Stratified split (sÄ±nÄ±f dengesi korundu)

4. **Class Balancing:**
   - `class_weight='balanced'` parametresi kullanÄ±ldÄ±

---

## ğŸ“‰ Model Hiperparametreleri

### Decision Tree
```python
DecisionTreeClassifier(
    max_depth=6,              # Ã‡ok dallÄ± olmasÄ±n
    min_samples_split=100,    # Dallanma iÃ§in min Ã¶rnek
    min_samples_leaf=50,      # Her yaprakta min Ã¶rnek
    criterion='gini',         # BÃ¶lÃ¼nme kriteri
    class_weight='balanced'   # SÄ±nÄ±f dengesi
)
```

### Random Forest
```python
RandomForestClassifier(
    n_estimators=100,         # 100 aÄŸaÃ§
    max_depth=6,              # Her aÄŸaÃ§ iÃ§in max derinlik
    min_samples_split=100,
    min_samples_leaf=50,
    criterion='gini',
    class_weight='balanced',
    n_jobs=-1                 # Paralel iÅŸleme
)
```

---

## ğŸ“‚ Proje YapÄ±sÄ±

```
employee-attrition/
â”œâ”€â”€ aug_train.csv                      # EÄŸitim verisi
â”œâ”€â”€ aug_test.csv                       # Test verisi
â”œâ”€â”€ sample_submission.csv              # Submission ÅŸablonu
â”œâ”€â”€ decision_tree_model.py             # Decision Tree modeli
â”œâ”€â”€ compare_models.py                  # Model karÅŸÄ±laÅŸtÄ±rmasÄ±
â”œâ”€â”€ decision_tree_analysis.png         # DT analiz grafikleri
â”œâ”€â”€ decision_tree_full.png             # Tam aÄŸaÃ§ yapÄ±sÄ±
â”œâ”€â”€ model_comparison.png               # KarÅŸÄ±laÅŸtÄ±rma grafikleri
â”œâ”€â”€ submission_decision_tree.csv       # DT tahminleri
â”œâ”€â”€ submission_random_forest.csv       # RF tahminleri
â””â”€â”€ README.md                          # Bu dosya
```

---

## ğŸ¯ SonuÃ§lar ve Ã–neriler

### SonuÃ§lar:
1. **Random Forest** daha yÃ¼ksek accuracy (%76.6) saÄŸladÄ±
2. **Decision Tree** daha yÃ¼ksek recall (%80.2) gÃ¶sterdi
3. **Random Forest** daha dengeli performans sundu
4. Overfitting, Random Forest'ta daha az

### Ã–neriler:
- **Ãœretim iÃ§in**: Random Forest (daha gÃ¼venilir)
- **AÃ§Ä±klama gerekiyorsa**: Decision Tree (yorumlanabilir)
- **HÄ±zlÄ± prototip**: Decision Tree (daha hÄ±zlÄ±)
- **En iyi performans**: Random Forest veya Gradient Boosting

---

## ğŸ”® Gelecek GeliÅŸtirmeler

- [ ] Hyperparameter tuning (GridSearchCV)
- [ ] Feature engineering
- [ ] SMOTE ile class balancing
- [ ] Gradient Boosting modelleri (XGBoost, LightGBM)
- [ ] Cross-validation
- [ ] Feature selection
- [ ] Ensemble of ensembles

---

## ğŸ“§ Ä°letiÅŸim

Bu proje, Decision Tree ve Random Forest arasÄ±ndaki farklarÄ± gÃ¶stermek amacÄ±yla oluÅŸturulmuÅŸtur.

**Tarih:** AralÄ±k 2025

---

## ğŸ“œ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r.
